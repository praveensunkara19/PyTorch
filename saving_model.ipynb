{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "899f3c08",
   "metadata": {},
   "source": [
    "#### Three Ways to save the models\n",
    "```\n",
    "torch.save(arg, PATH) #uses python pickel module to serialize the model\n",
    "\n",
    "torch.load(PATH)\n",
    "\n",
    "model.load_state_dict(arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e00d34",
   "metadata": {},
   "source": [
    "1. complete model \n",
    "(Lazy approch)\n",
    "```\n",
    "torch.save(model, PATH)\n",
    "\n",
    "#model classes must be defined somewhere\n",
    "model = torch.load(PATH)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dis adv: serialized data bount to specific classes and exact directory structure  when model is saved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdc1084",
   "metadata": {},
   "source": [
    "2. STATE DICT\n",
    "```\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# model must be created again with parameters\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a259789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f72f41eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = nn.Sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "model  = Model(n_input_features=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2711cac",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58c152ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = 'models\\\\model.pth'\n",
    "\n",
    "torch.save(model, FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d270efc",
   "metadata": {},
   "source": [
    "Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1f6e093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (linear): Linear(in_features=6, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1-type\n",
    "loaded_model = torch.load('models\\\\model.pth', weights_only=False)\n",
    "loaded_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b001cece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2798,  0.1442,  0.2186, -0.0446,  0.1144,  0.3999]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2020], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7bce82",
   "metadata": {},
   "source": [
    "#2-type -> packs the weights parameters with the model itself ease to load the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f337f0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'linear.weight': tensor([[ 0.2798,  0.1442,  0.2186, -0.0446,  0.1144,  0.3999]]), 'linear.bias': tensor([-0.2020])})\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f9314",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45b1a99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[ 0.2798,  0.1442,  0.2186, -0.0446,  0.1144,  0.3999]])),\n",
       "             ('linear.bias', tensor([-0.2020]))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = torch.load(FILE)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "934a3a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (linear): Linear(in_features=6, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = Model(n_input_features=6)\n",
    "loaded_model.load_state_dict(torch.load(FILE))\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "675addc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2798,  0.1442,  0.2186, -0.0446,  0.1144,  0.3999]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2020], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in loaded_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8201567",
   "metadata": {},
   "source": [
    "### Checkpoints\n",
    "\n",
    "* are used to save the models during training or resume for further training\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b11d6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [0, 1]}]}\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39235d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check points contais all the metadata, model weights, and parametric values, learning_rate, optim_state\n",
    "\n",
    "checkpoints = {\n",
    "    'epoch': 90,\n",
    "    'model_state': model.state_dict(),\n",
    "    'optim_state': optimizer.state_dict()\n",
    "\n",
    "}\n",
    "\n",
    "torch.save(checkpoints, 'models\\\\checkpoints.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d3739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Optimizer.state_dict of SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "loaded_checkpoints = torch.load('models\\\\checkpoints.pth')\n",
    "epoch = loaded_checkpoints['epoch']\n",
    "\n",
    "model = Model(n_input_features=6)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0)\n",
    "\n",
    "\n",
    "#updating the new model parameters with the previously saved checkpoints with the load_state_dict()\n",
    "model.load_state_dict(checkpoints['model_state'])\n",
    "optimizer.load_state_dict(checkpoints['optim_state'])\n",
    "\n",
    "print(optimizer.state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8362924",
   "metadata": {},
   "source": [
    "GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803ebd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save on GPU, load on CPU\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eae386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save on GPU and Load on GPU\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model.save(device)\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d45675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save on CPU, Load on GPU\n",
    "\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH, map_location='cuda:0'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e804480c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892dc481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
